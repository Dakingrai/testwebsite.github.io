---
layout: default
title: Home
---

<div class="profile-container">
  <img src="assets/images/profile.jpg" alt="My Profile Picture" class="profile-img">
  
  <div class="profile-text">
    <p>Hi, I'm a PhD student at <a href="https://cs.gmu.edu/" target="_blank">George Mason University</a> advised by <a href="https://ziyuyao.org/" target="_blank"> Prof. Ziyu Yao</a>. Iâ€™m interested in understanding how language models work and applying those insights to practical applications such as improving improve their capabilities and controllability.  </p>
    
    <p> I am actively seeking a <span style="font-weight: bold;">Summer 2026 internship</span>. My recent work centers around <a href="https://arxiv.org/pdf/2407.02646" target="_blank"> mechanistic interpretability (MI) </a> of language models, aiming to better understand how model perform reasoning and to leverage those insights to <span style="font-weight: bold;">improve their reasoning capabilities</span>.  </p>

    <!-- where I'm currently interested in developing a top-down MI framework for explaining model behaviors across levels of analysis, from mechanistic components (e.g., features, circuits) to high-level cognitive-like behaviors (e.g., reasoning). This is motivated by the uncertainty that low-level understanding will explain higher-level emergent behaviors. -->
    
    <!-- <small> Misc: I was born and grew up in Nepal. Besides research, I like taking pictures and traveling. </small> -->
    
    <p>
      <a href="https://x.com/DakingRai" target="_blank">Twitter</a> / <a href="/assets/files/resume.pdf" target="_blank">Resume</a> / <a href="https://scholar.google.com/citations?hl=en&user=M5r2DHIAAAAJ" target="_blank">Google Scholar</a> / <a href="https://www.linkedin.com/in/daking-rai-901593112/" target="_blank">LinkedIn</a>
    </p>
  </div>
</div>

<h2>News & Updates</h2>

<div class="news-box">
  
  <p><strong>Upcoming events:</strong></p>

  <div class="news-item">
    <strong>2025-12-10</strong> Attending NeurIPS (San Diego) to present my work on <a href="#" target="_blank">Balanced Parentheses Errors</a>.
  </div>

  <div class="news-item">
    <strong>2025-11-15</strong> Defending my thesis proposal at George Mason University.
  </div>

  <br> <p><strong>Past news:</strong></p>

  <div class="news-item">
    <strong>2025-10-06</strong> Co-organized "The First Workshop on the Application of LLM Explainability to Reasoning and Planning".
  </div>

  <div class="news-item">
    <strong>2025-09-20</strong> Released the preprint for <a href="#" target="_blank">Failure by Interference</a>.
  </div>

  <div class="news-item">
    <strong>2025-08-01</strong> Released a new dataset for arithmetic reasoning in LLMs.
  </div>

  <div class="news-item">
    <strong>2025-05-01</strong> Started internship at [Company Name].
  </div>
  
  <div class="news-item">
    <strong>2024-12-14</strong> Presented poster at NeurIPS 2024.
  </div>

</div>

## Papers

<div class="paper-item">
  <div class="paper-date">NeurIPS 2025</div>
  <div class="paper-details">
    An Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones. (<a href="https://arxiv.org/pdf/2507.00322">Paper</a>)
  </div>
</div>

<div class="paper-item">
  <div class="paper-date">EMNLP 2025</div>
  <div class="paper-details">
    All for one: Llms solve mental math at the last token with information transferred from other tokens. (<a href="https://aclanthology.org/2025.emnlp-main.1565.pdf">Paper</a>)
  </div>
</div>

<div class="paper-item">
  <div class="paper-date">Pre-print 2025</div>
  <div class="paper-details">
    A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models. (<a href="https://arxiv.org/abs/2407.02646">Paper</a>)
  </div>
</div>


<div class="paper-item">
  <div class="paper-date">Pre-print 2025</div>
  <div class="paper-details">
    A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models. (<a href="https://arxiv.org/abs/2407.02646">Paper</a>)
  </div>
</div>

<div class="paper-item">
  <div class="paper-date">EMNLP 2025</div>
  <div class="paper-details">
    A survey on sparse autoencoders: Interpreting the internal mechanisms of large language models. (<a href="https://arxiv.org/pdf/2503.05613">Paper</a>)
  </div>
</div>


<div class="paper-item">
  <div class="paper-date">ACL 2024</div>
  <div class="paper-details">
    An investigation of neuron activation as a unified lens to explain chain-of-thought eliciting arithmetic reasoning of llms. (<a href="https://arxiv.org/pdf/2406.12288?">Paper</a>)
  </div>
</div>


## News and Events

<div class="paper-item">
  <div class="paper-date">NeurIPS 2025</div>
  <div class="paper-details">
    An Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones. (<a href="https://arxiv.org/pdf/2507.00322">Paper</a>)
  </div>
</div>


